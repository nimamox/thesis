\begin{abstract_en}
Brain's extraordinary capability to process this tremendous amount of information in a parallel fashion and its sophisticated structure has indeed made it the most complex organ in the universe. Although with no doubt the are distinct regions of brain in terms of anatomy, physiology and behaviourism, and considering the modular function of the brain, a considerable amount of local circuitry in cortex are realized randomly. The inability of genome to contain this massive description of synaptic connections is an evidence for this necessary involvement of randomness and motivates more attention from the academia. This study aims to investigate the potentials of Reservoir Computing for visual pattern recognition. Liquid State Machines, as a form Reservoir Computing based on neural building blocks, have recently gained a lot of attention and is already suggested for some engineering applications. LSMs basically map the input to to a space of higher dimensions and therefore make distinguishing spatiotemporal patterns more feasible; much like what is achieved by kernels in Support Vector Machines, except LSMs are more biologically plausible to this end. Here, various approaches are incorporated to help us investigate the role of network topology on the performance of an LSM. Moreover, a new method for representation of LSMs' internal states which helps to achieve a better discrimination among samples is proposed. We also suggest a new criterion to assess the separation property of an LSM.
\end{abstract_en}
\begin{keyword_en}
Reservoir Computing \sep Liquid State Machines \sep Spiking Neural Networks \sep Visual Pattern Recognition
\end{keyword_en}